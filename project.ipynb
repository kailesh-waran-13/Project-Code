{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os   \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_stem_image(input_path):\n",
    "    # Read the image\n",
    "    original_image = cv2.imread(input_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur for noise reduction\n",
    "    blurred_image = cv2.GaussianBlur(grayscale_image, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    _, thresholded_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Perform morphological operations (erosion and dilation)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morph_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(morph_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out small contours (noise)\n",
    "    min_contour_area = 100\n",
    "    valid_contours = [contour for contour in contours if cv2.contourArea(contour) > min_contour_area]\n",
    "\n",
    "    # Draw the contours on a blank image\n",
    "    result_image = np.zeros_like(original_image)\n",
    "    cv2.drawContours(result_image, valid_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    return original_image, result_image\n",
    "\n",
    "def preprocess_stem_images(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get a list of all image files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the full path to the input image\n",
    "        input_path = os.path.join(input_folder, image_file)\n",
    "\n",
    "        # Preprocess each image\n",
    "        original_image, result_image = preprocess_stem_image(input_path)\n",
    "\n",
    "        # Save the preprocessed image to the output folder\n",
    "        output_path = os.path.join(output_folder, f\"preprocessed_{image_file}\")\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "        # Display the original and preprocessed images using Matplotlib\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Original Image - {image_file}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Preprocessed Image - {image_file}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Pause execution to allow time for images to be displayed\n",
    "    plt.show(block=True)\n",
    "\n",
    "# Example usage\n",
    "input_folder = r'Dataset'\n",
    "output_folder = r'Preprocessed'\n",
    "preprocess_stem_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction using ResNet50 Model after Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def extract_resnet50_features(input_folder):\n",
    "    # Load pre-trained ResNet50 model (excluding the top layer)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Create a model using the base model's input and output\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "    # Get a list of all preprocessed image files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.startswith('preprocessed_') and f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the full path to the preprocessed image\n",
    "        input_path_preprocessed = os.path.join(input_folder, image_file)\n",
    "\n",
    "        # Read the preprocessed image\n",
    "        preprocessed_image = cv2.imread(input_path_preprocessed)\n",
    "\n",
    "        # Resize the image to match the input size expected by ResNet50 (224x224)\n",
    "        resized_image = cv2.resize(preprocessed_image, (224, 224))\n",
    "\n",
    "        # Preprocess the image for ResNet50 model\n",
    "        input_data = preprocess_input(np.expand_dims(resized_image, axis=0))\n",
    "\n",
    "        # Extract features using ResNet50\n",
    "        feature_vector = model.predict(input_data)\n",
    "\n",
    "        features.append(feature_vector.flatten())  # Flatten the feature vector for simplicity\n",
    "\n",
    "        # Save the featured image to the \"Featured\" folder\n",
    "        output_folder_featured = 'Featured'\n",
    "        output_path_featured = os.path.join(output_folder_featured, f\"feature_image_{image_file[13:]}\")\n",
    "        cv2.imwrite(output_path_featured, preprocessed_image)\n",
    "\n",
    "    return np.array(features), image_files\n",
    "\n",
    "def plot_pca(features, image_files):\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    # Scatter plot the reduced features\n",
    "    plt.scatter(reduced_features[:, 0], reduced_features[:, 1], marker='o', c='blue')\n",
    "    plt.title('PCA of ResNet50 Features')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "\n",
    "def display_comparison(input_folder_preprocessed, output_folder_featured, image_files):\n",
    "    for image_file in image_files:\n",
    "        # Construct the full path to the preprocessed and featured images\n",
    "        input_path_preprocessed = os.path.join(input_folder_preprocessed, image_file)\n",
    "        input_path_featured = os.path.join(output_folder_featured, f\"feature_image_{image_file[13:]}\")\n",
    "\n",
    "        # Read the preprocessed and featured images\n",
    "        preprocessed_image = cv2.imread(input_path_preprocessed)\n",
    "        featured_image = cv2.imread(input_path_featured)\n",
    "\n",
    "        # Display the original, preprocessed, and featured images using Matplotlib\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Preprocessed Image - {image_file}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cv2.cvtColor(featured_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Featured Image - {image_file[13:]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "input_folder_preprocessed = 'Preprocessed'\n",
    "output_folder_featured = 'Featured'\n",
    "features, image_files = extract_resnet50_features(input_folder_preprocessed)\n",
    "\n",
    "# Plot PCA of the extracted features\n",
    "plot_pca(features, image_files)\n",
    "\n",
    "# Display the comparison of original, preprocessed, and featured images\n",
    "display_comparison(input_folder_preprocessed, output_folder_featured, image_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling After Featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the folder containing your images\n",
    "input_folder_path = \"Featured\"\n",
    "output_folder_path = \"maxPooled\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Function to perform max pooling on an image\n",
    "def max_pool_image(image):\n",
    "    # Assuming 'image' is a NumPy array representing the image\n",
    "    pooled_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    return pooled_image\n",
    "\n",
    "# Iterate through images in the input folder\n",
    "for filename in os.listdir(input_folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Read the original image\n",
    "        original_image_path = os.path.join(input_folder_path, filename)\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "\n",
    "        # Define the new dimensions for the pooled image\n",
    "        new_width = original_image.shape[1] // 2  # Adjust as needed\n",
    "        new_height = original_image.shape[0] // 2  # Adjust as needed\n",
    "\n",
    "        # Perform max pooling on the image\n",
    "        pooled_image = max_pool_image(original_image)\n",
    "\n",
    "        # Save the pooled image in the output folder\n",
    "        pooled_image_path = os.path.join(output_folder_path, f\"maxPooled_{filename[14:]}\")\n",
    "        cv2.imwrite(pooled_image_path, pooled_image)\n",
    "\n",
    "        # Display the images side by side for comparison\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"{filename}\")\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f\"pooled:{filename}\")\n",
    "        plt.imshow(cv2.cvtColor(pooled_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the folder containing your images\n",
    "input_folder_path = \"maxPooled\"\n",
    "output_folder_path = \"SplitData\"\n",
    "\n",
    "# Create the output folders if they don't exist\n",
    "for folder_name in [\"train\", \"test\", \"validation\"]:\n",
    "    os.makedirs(os.path.join(output_folder_path, folder_name), exist_ok=True)\n",
    "\n",
    "# Lists to store file paths\n",
    "file_paths = []\n",
    "\n",
    "# Iterate through images in the input folder\n",
    "for filename in os.listdir(input_folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Append file path\n",
    "        file_paths.append(os.path.join(input_folder_path, filename))\n",
    "\n",
    "# Split the data into train, test, and validation sets\n",
    "train_files, test_val_files = train_test_split(file_paths, test_size=0.15, random_state=42)\n",
    "test_files, val_files = train_test_split(test_val_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Move images to the corresponding folders\n",
    "for filepath in train_files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    destination_path = os.path.join(output_folder_path, \"train\", filename)\n",
    "    os.replace(filepath, destination_path)\n",
    "\n",
    "for filepath in test_files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    destination_path = os.path.join(output_folder_path, \"test\", filename)\n",
    "    os.replace(filepath, destination_path)\n",
    "\n",
    "for filepath in val_files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    destination_path = os.path.join(output_folder_path, \"validation\", filename)\n",
    "    os.replace(filepath, destination_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
